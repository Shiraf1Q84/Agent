import streamlit as st
import google.generativeai as genai
from typing import Dict, Any
import json

# Streamlit UIè¨­å®š
st.set_page_config(page_title="Geminiã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆ", layout="wide")

# ã‚«ã‚¹ã‚¿ãƒ CSS
st.markdown("""
<style>
    .main-content { max-width: 1200px; margin: auto; padding: 20px; }
    .chat-container { border: 1px solid #ddd; border-radius: 10px; padding: 20px; margin-bottom: 20px; }
    .user-message { background-color: #e6f3ff; padding: 10px; border-radius: 10px; margin-bottom: 10px; }
    .assistant-message { background-color: #f0f0f0; padding: 10px; border-radius: 10px; margin-bottom: 10px; }
    .reasoning-container { border-left: 3px solid #4CAF50; padding-left: 20px; margin-top: 20px; }
    .stTextInput>div>div>input { min-height: 50px; }
</style>
""", unsafe_allow_html=True)

# ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã®åˆæœŸåŒ–
if 'chat_history' not in st.session_state:
    st.session_state.chat_history = []
if 'reasoning_history' not in st.session_state:
    st.session_state.reasoning_history = []

# ãƒ¢ãƒƒã‚¯ãƒ„ãƒ¼ãƒ«ã®å®šç¾©
def search_web(query: str) -> str:
    return f"Webæ¤œç´¢çµæœ: {query}ã«é–¢ã™ã‚‹æƒ…å ±"

def fetch_page(url: str) -> str:
    return f"{url}ã®å†…å®¹"

tools = [
    {
        "name": "search_web",
        "description": "Webæ¤œç´¢ã‚’è¡Œã„ã€çµæœã‚’è¿”ã—ã¾ã™ã€‚",
        "parameters": {
            "type": "object",
            "properties": {
                "query": {"type": "string", "description": "æ¤œç´¢ã‚¯ã‚¨ãƒª"}
            },
            "required": ["query"]
        }
    },
    {
        "name": "fetch_page",
        "description": "æŒ‡å®šã•ã‚ŒãŸURLã®Webãƒšãƒ¼ã‚¸ã®å†…å®¹ã‚’å–å¾—ã—ã¾ã™ã€‚",
        "parameters": {
            "type": "object",
            "properties": {
                "url": {"type": "string", "description": "å–å¾—ã™ã‚‹Webãƒšãƒ¼ã‚¸ã®URL"}
            },
            "required": ["url"]
        }
    }
]

# Geminiãƒ¢ãƒ‡ãƒ«ã®è¨­å®šã¨åˆæœŸåŒ–
def initialize_model(api_key: str):
    genai.configure(api_key=api_key)
    return genai.GenerativeModel('gemini-pro')

# ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®å®Ÿè¡Œã¨ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°
def run_agent(model, user_input: str) -> None:
    system_prompt = """
    ã‚ãªãŸã¯é«˜åº¦ãªAIã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ã«ç­”ãˆã‚‹ãŸã‚ã«ã€ä»¥ä¸‹ã®ã‚¹ãƒ†ãƒƒãƒ—ã‚’è¸ã‚“ã§ãã ã•ã„ï¼š
    1. ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ã‚’ç†è§£ã—ã€é©åˆ‡ãªæ¤œç´¢æˆ¦ç•¥ã‚’ç«‹ã¦ã‚‹ã€‚
    2. å¿…è¦ã«å¿œã˜ã¦ã€æä¾›ã•ã‚Œã¦ã„ã‚‹ãƒ„ãƒ¼ãƒ«ï¼ˆWebæ¤œç´¢ã€ãƒšãƒ¼ã‚¸å–å¾—ï¼‰ã‚’ä½¿ç”¨ã—ã¦æƒ…å ±ã‚’åé›†ã™ã‚‹ã€‚
    3. åé›†ã—ãŸæƒ…å ±ã‚’åˆ†æã—ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ã«å¯¾ã™ã‚‹å›ç­”ã‚’ä½œæˆã™ã‚‹ã€‚
    4. å›ç­”ã®æ ¹æ‹ ã¨ãªã‚‹æƒ…å ±æºã‚’æ˜è¨˜ã™ã‚‹ã€‚
    5. æ¨è«–éç¨‹ã‚’è©³ç´°ã«èª¬æ˜ã—ã€å„ã‚¹ãƒ†ãƒƒãƒ—ã§ä½•ã‚’è€ƒãˆã€ã©ã®ã‚ˆã†ãªè¡Œå‹•ã‚’ã¨ã£ãŸã‹ã‚’æ˜ç¢ºã«ã™ã‚‹ã€‚

    å›ç­”ã¯ä»¥ä¸‹ã®å½¢å¼ã§å‡ºåŠ›ã—ã¦ãã ã•ã„ï¼š
    ```json
    {
        "æ€è€ƒ": "ç¾åœ¨ã®æ€è€ƒãƒ—ãƒ­ã‚»ã‚¹ã®èª¬æ˜",
        "è¡Œå‹•": {
            "tool": "ä½¿ç”¨ã™ã‚‹ãƒ„ãƒ¼ãƒ«å",
            "params": {
                "param1": "å€¤1",
                "param2": "å€¤2"
            }
        },
        "è¦³å¯Ÿ": "ãƒ„ãƒ¼ãƒ«ã®å®Ÿè¡Œçµæœã‚„è¦³å¯Ÿã—ãŸå†…å®¹",
        "çµè«–": "æœ€çµ‚çš„ãªå›ç­”ã‚„çµè«–"
    }
    ```

    ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ã«ç­”ãˆã‚‹ã¾ã§ã€ã“ã®ãƒ—ãƒ­ã‚»ã‚¹ã‚’ç¹°ã‚Šè¿”ã—ã¦ãã ã•ã„ã€‚
    """

    prompt = f"{system_prompt}\n\nãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•: {user_input}\n\nå›ç­”:"
    
    reasoning_placeholder = st.empty()
    response_placeholder = st.empty()
    full_response = ""
    reasoning_steps = []

    for chunk in model.generate_content(prompt, tools=tools, stream=True):
        if chunk.text:
            full_response += chunk.text
            try:
                response_json = json.loads(full_response)
                display_reasoning(response_json, reasoning_placeholder)
                reasoning_steps.append(response_json)
            except json.JSONDecodeError:
                pass

    # ãƒ„ãƒ¼ãƒ«ã®å®Ÿè¡Œï¼ˆå®Ÿéš›ã®APIã‚³ãƒ¼ãƒ«ã®ä»£ã‚ã‚Šã«ãƒ¢ãƒƒã‚¯ï¼‰
    if reasoning_steps and "è¡Œå‹•" in reasoning_steps[-1] and "tool" in reasoning_steps[-1]["è¡Œå‹•"]:
        tool_name = reasoning_steps[-1]["è¡Œå‹•"]["tool"]
        if tool_name == "search_web":
            result = search_web(reasoning_steps[-1]["è¡Œå‹•"]["params"]["query"])
        elif tool_name == "fetch_page":
            result = fetch_page(reasoning_steps[-1]["è¡Œå‹•"]["params"]["url"])
        else:
            result = "æœªçŸ¥ã®ãƒ„ãƒ¼ãƒ«ãŒå‘¼ã³å‡ºã•ã‚Œã¾ã—ãŸã€‚"
        
        reasoning_steps[-1]["è¦³å¯Ÿ"] = result
        display_reasoning(reasoning_steps[-1], reasoning_placeholder)

    # æœ€çµ‚çš„ãªçµè«–ã‚’è¡¨ç¤º
    final_conclusion = reasoning_steps[-1].get("çµè«–", "çµè«–ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
    response_placeholder.markdown(f"**å›ç­”:** {final_conclusion}")

    # ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã¨æ¨è«–å±¥æ­´ã«è¿½åŠ 
    st.session_state.chat_history.append({"role": "assistant", "content": final_conclusion})
    st.session_state.reasoning_history.append(reasoning_steps)

def display_reasoning(response: Dict[str, Any], placeholder: st.empty) -> None:
    markdown = ""
    if "æ€è€ƒ" in response:
        markdown += f"**æ€è€ƒ:** {response['æ€è€ƒ']}\n\n"
    if "è¡Œå‹•" in response:
        markdown += f"**è¡Œå‹•:** {json.dumps(response['è¡Œå‹•'], ensure_ascii=False, indent=2)}\n\n"
    if "è¦³å¯Ÿ" in response:
        markdown += f"**è¦³å¯Ÿ:** {response['è¦³å¯Ÿ']}\n\n"
    if "çµè«–" in response:
        markdown += f"**çµè«–:** {response['çµè«–']}\n\n"
    placeholder.markdown(markdown)

# ãƒ¡ã‚¤ãƒ³é–¢æ•°
def main():
    st.title("Geminiã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆ")

    # 2ã‚«ãƒ©ãƒ ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆ
    col1, col2 = st.columns([2, 1])

    with col1:
        st.markdown("<div class='main-content'>", unsafe_allow_html=True)
        
        # APIã‚­ãƒ¼ã®å…¥åŠ›
        api_key = st.text_input("Google API Keyã‚’å…¥åŠ›ã—ã¦ãã ã•ã„", type="password")

        if api_key:
            model = initialize_model(api_key)

            # ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã®è¡¨ç¤º
            st.markdown("<div class='chat-container'>", unsafe_allow_html=True)
            for message in st.session_state.chat_history:
                if message["role"] == "user":
                    st.markdown(f"<div class='user-message'>ğŸ‘¤ {message['content']}</div>", unsafe_allow_html=True)
                else:
                    st.markdown(f"<div class='assistant-message'>ğŸ¤– {message['content']}</div>", unsafe_allow_html=True)
            st.markdown("</div>", unsafe_allow_html=True)

            # ãƒ¦ãƒ¼ã‚¶ãƒ¼å…¥åŠ›
            user_input = st.text_input("è³ªå•ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„", key="user_input")
            if user_input:
                st.session_state.chat_history.append({"role": "user", "content": user_input})
                st.markdown(f"<div class='user-message'>ğŸ‘¤ {user_input}</div>", unsafe_allow_html=True)

                with st.spinner("å›ç­”ã‚’ç”Ÿæˆä¸­..."):
                    run_agent(model, user_input)

        else:
            st.warning("Google API Keyã‚’å…¥åŠ›ã—ã¦ãã ã•ã„")

        st.markdown("</div>", unsafe_allow_html=True)

    with col2:
        st.markdown("<div class='reasoning-container'>", unsafe_allow_html=True)
        st.subheader("æ¨è«–éç¨‹")
        if st.session_state.reasoning_history:
            for step in st.session_state.reasoning_history[-1]:
                display_reasoning(step, st.empty())
        st.markdown("</div>", unsafe_allow_html=True)

if __name__ == "__main__":
    main()
